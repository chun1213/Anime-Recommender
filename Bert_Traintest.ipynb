{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Bert_Traintest",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WiJtVpCGqCxu",
        "outputId": "3ea0f1f2-8b9c-4124-8044-eabe10050ac6"
      },
      "source": [
        "!git clone https://github.com/jaywonchung/BERT4Rec-VAE-Pytorch  # clone repo"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'BERT4Rec-VAE-Pytorch'...\n",
            "remote: Enumerating objects: 166, done.\u001b[K\n",
            "remote: Total 166 (delta 0), reused 0 (delta 0), pack-reused 166\u001b[K\n",
            "Receiving objects: 100% (166/166), 3.05 MiB | 14.65 MiB/s, done.\n",
            "Resolving deltas: 100% (61/61), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBVw9iqQqQXP",
        "outputId": "e16c6ecc-4ce0-4b02-ab35-16609d5ba424"
      },
      "source": [
        "%cd BERT4Rec-VAE-Pytorch/\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/BERT4Rec-VAE-Pytorch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "While the requirements are installing, upload either the ratings or the preprocessed pickle files.\n",
        "If you are doing inference, also upload the new template and main files.\n",
        "\n",
        "#Make sure you restart runtime after you change out the files!"
      ],
      "metadata": {
        "id": "sc0k8QnMXs02"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WJyHn29fqphh",
        "outputId": "1b239cf3-0b72-4563-9335-2eeedb0f1b06"
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wget==3.2\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "Collecting tqdm==4.36.1\n",
            "  Downloading tqdm-4.36.1-py2.py3-none-any.whl (52 kB)\n",
            "\u001b[K     |████████████████████████████████| 52 kB 991 kB/s \n",
            "\u001b[?25hCollecting numpy==1.16.2\n",
            "  Downloading numpy-1.16.2-cp37-cp37m-manylinux1_x86_64.whl (17.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 17.3 MB 104 kB/s \n",
            "\u001b[?25hCollecting torch==1.3.0\n",
            "  Downloading torch-1.3.0-cp37-cp37m-manylinux1_x86_64.whl (773.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 773.1 MB 12 kB/s \n",
            "\u001b[?25hCollecting tb-nightly==2.1.0a20191121\n",
            "  Downloading tb_nightly-2.1.0a20191121-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 36.1 MB/s \n",
            "\u001b[?25hCollecting pandas==0.25.0\n",
            "  Downloading pandas-0.25.0-cp37-cp37m-manylinux1_x86_64.whl (10.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.4 MB 22.2 MB/s \n",
            "\u001b[?25hCollecting scipy==1.3.2\n",
            "  Downloading scipy-1.3.2-cp37-cp37m-manylinux1_x86_64.whl (25.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 25.2 MB 1.7 MB/s \n",
            "\u001b[?25hCollecting future==0.18.2\n",
            "  Downloading future-0.18.2.tar.gz (829 kB)\n",
            "\u001b[K     |████████████████████████████████| 829 kB 38.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly==2.1.0a20191121->-r requirements.txt (line 5)) (1.15.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly==2.1.0a20191121->-r requirements.txt (line 5)) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tb-nightly==2.1.0a20191121->-r requirements.txt (line 5)) (3.3.6)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tb-nightly==2.1.0a20191121->-r requirements.txt (line 5)) (1.35.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly==2.1.0a20191121->-r requirements.txt (line 5)) (57.4.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tb-nightly==2.1.0a20191121->-r requirements.txt (line 5)) (0.37.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tb-nightly==2.1.0a20191121->-r requirements.txt (line 5)) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tb-nightly==2.1.0a20191121->-r requirements.txt (line 5)) (0.4.6)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tb-nightly==2.1.0a20191121->-r requirements.txt (line 5)) (0.12.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tb-nightly==2.1.0a20191121->-r requirements.txt (line 5)) (1.43.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly==2.1.0a20191121->-r requirements.txt (line 5)) (3.17.3)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from pandas==0.25.0->-r requirements.txt (line 6)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas==0.25.0->-r requirements.txt (line 6)) (2018.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tb-nightly==2.1.0a20191121->-r requirements.txt (line 5)) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tb-nightly==2.1.0a20191121->-r requirements.txt (line 5)) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tb-nightly==2.1.0a20191121->-r requirements.txt (line 5)) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tb-nightly==2.1.0a20191121->-r requirements.txt (line 5)) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tb-nightly==2.1.0a20191121->-r requirements.txt (line 5)) (4.10.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tb-nightly==2.1.0a20191121->-r requirements.txt (line 5)) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tb-nightly==2.1.0a20191121->-r requirements.txt (line 5)) (3.10.0.2)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tb-nightly==2.1.0a20191121->-r requirements.txt (line 5)) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tb-nightly==2.1.0a20191121->-r requirements.txt (line 5)) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tb-nightly==2.1.0a20191121->-r requirements.txt (line 5)) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tb-nightly==2.1.0a20191121->-r requirements.txt (line 5)) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tb-nightly==2.1.0a20191121->-r requirements.txt (line 5)) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tb-nightly==2.1.0a20191121->-r requirements.txt (line 5)) (3.1.1)\n",
            "Building wheels for collected packages: wget, future\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9675 sha256=f58d5b427782129c73ab268ac78a1bef623166a4b7c0586fe4f97a7d3f656549\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/b6/7c/0e63e34eb06634181c63adacca38b79ff8f35c37e3c13e3c02\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=0c784c6609ca05c1c92a8baf838e14e68078d436b225f320c8df96eeefee7ade\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n",
            "Successfully built wget future\n",
            "Installing collected packages: numpy, wget, tqdm, torch, tb-nightly, scipy, pandas, future\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.62.3\n",
            "    Uninstalling tqdm-4.62.3:\n",
            "      Successfully uninstalled tqdm-4.62.3\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.10.0+cu111\n",
            "    Uninstalling torch-1.10.0+cu111:\n",
            "      Successfully uninstalled torch-1.10.0+cu111\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.1.5\n",
            "    Uninstalling pandas-1.1.5:\n",
            "      Successfully uninstalled pandas-1.1.5\n",
            "  Attempting uninstall: future\n",
            "    Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xarray 0.18.2 requires numpy>=1.17, but you have numpy 1.16.2 which is incompatible.\n",
            "xarray 0.18.2 requires pandas>=1.0, but you have pandas 0.25.0 which is incompatible.\n",
            "torchvision 0.11.1+cu111 requires torch==1.10.0, but you have torch 1.3.0 which is incompatible.\n",
            "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.3.0 which is incompatible.\n",
            "torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.3.0 which is incompatible.\n",
            "spacy 2.2.4 requires tqdm<5.0.0,>=4.38.0, but you have tqdm 4.36.1 which is incompatible.\n",
            "scikit-image 0.18.3 requires numpy>=1.16.5, but you have numpy 1.16.2 which is incompatible.\n",
            "pywavelets 1.2.0 requires numpy>=1.17.3, but you have numpy 1.16.2 which is incompatible.\n",
            "pyerfa 2.0.0.1 requires numpy>=1.17, but you have numpy 1.16.2 which is incompatible.\n",
            "pyarrow 3.0.0 requires numpy>=1.16.6, but you have numpy 1.16.2 which is incompatible.\n",
            "panel 0.12.1 requires tqdm>=4.48.0, but you have tqdm 4.36.1 which is incompatible.\n",
            "kapre 0.3.6 requires numpy>=1.18.5, but you have numpy 1.16.2 which is incompatible.\n",
            "jaxlib 0.1.71+cuda111 requires numpy>=1.18, but you have numpy 1.16.2 which is incompatible.\n",
            "jax 0.2.25 requires numpy>=1.18, but you have numpy 1.16.2 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas~=1.1.0; python_version >= \"3.0\", but you have pandas 0.25.0 which is incompatible.\n",
            "fbprophet 0.7.1 requires pandas>=1.0.4, but you have pandas 0.25.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "cupy-cuda111 9.4.0 requires numpy<1.24,>=1.17, but you have numpy 1.16.2 which is incompatible.\n",
            "astropy 4.3.1 requires numpy>=1.17, but you have numpy 1.16.2 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed future-0.18.2 numpy-1.16.2 pandas-0.25.0 scipy-1.3.2 tb-nightly-2.1.0a20191121 torch-1.3.0 tqdm-4.36.1 wget-3.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "pandas"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RUN FROM HERE TO TRAIN NEW MODEL**\n",
        "You may want to run this once to create the apropriate data folders"
      ],
      "metadata": {
        "id": "cfuqUYBUYnPE"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wK4y6RFNqTG_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f018ce51-74ec-4ff9-cb55-aab232839f25"
      },
      "source": [
        "!python main.py --template train_bert"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tqdm/std.py:648: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
            "  from pandas import Panel\n",
            "Input 1 for ml-1m, 20 for ml-20m: 1\n",
            "0\n",
            "Folder created: /content/BERT4Rec-VAE-Pytorch/experiments/test_2022-01-11_6\n",
            "{'anneal_cap': 0.2,\n",
            " 'bert_dropout': 0.1,\n",
            " 'bert_hidden_units': 256,\n",
            " 'bert_mask_prob': 0.15,\n",
            " 'bert_max_len': 100,\n",
            " 'bert_num_blocks': 2,\n",
            " 'bert_num_heads': 4,\n",
            " 'best_metric': 'NDCG@10',\n",
            " 'dae_dropout': 0.5,\n",
            " 'dae_hidden_dim': 600,\n",
            " 'dae_latent_dim': 200,\n",
            " 'dae_num_hidden': 0,\n",
            " 'dataloader_code': 'bert',\n",
            " 'dataloader_random_seed': 0.0,\n",
            " 'dataset_code': 'ml-1m',\n",
            " 'dataset_split_seed': 98765,\n",
            " 'decay_step': 25,\n",
            " 'device': 'cuda',\n",
            " 'device_idx': '0',\n",
            " 'enable_lr_schedule': True,\n",
            " 'eval_set_size': 500,\n",
            " 'experiment_description': 'test',\n",
            " 'experiment_dir': 'experiments',\n",
            " 'find_best_beta': False,\n",
            " 'gamma': 1.0,\n",
            " 'log_period_as_iter': 12800,\n",
            " 'lr': 0.001,\n",
            " 'metric_ks': [1,\n",
            "               5,\n",
            "               10,\n",
            "               20,\n",
            "               50,\n",
            "               100],\n",
            " 'min_rating': 0,\n",
            " 'min_sc': 0,\n",
            " 'min_uc': 5,\n",
            " 'mode': 'train',\n",
            " 'model_code': 'bert',\n",
            " 'model_init_seed': 0,\n",
            " 'num_epochs': 100,\n",
            " 'num_gpu': 1,\n",
            " 'optimizer': 'Adam',\n",
            " 'split': 'leave_one_out',\n",
            " 'template': 'train_bert',\n",
            " 'test_batch_size': 128,\n",
            " 'test_negative_sample_size': 100,\n",
            " 'test_negative_sampler_code': 'random',\n",
            " 'test_negative_sampling_seed': 98765,\n",
            " 'testing': False,\n",
            " 'total_anneal_steps': 2000,\n",
            " 'train_batch_size': 128,\n",
            " 'train_negative_sample_size': 0,\n",
            " 'train_negative_sampler_code': 'random',\n",
            " 'train_negative_sampling_seed': 0,\n",
            " 'trainer_code': 'bert',\n",
            " 'vae_dropout': 0.5,\n",
            " 'vae_hidden_dim': 600,\n",
            " 'vae_latent_dim': 200,\n",
            " 'vae_num_hidden': 0,\n",
            " 'val_batch_size': 128,\n",
            " 'weight_decay': 0}\n",
            "Already preprocessed. Skip preprocessing\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RUN FROM HERE IF YOU WANT TO USE PRETRAINED MODEL**"
      ],
      "metadata": {
        "id": "TVA7m4jXYWRt"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrXZb5I30_vs",
        "outputId": "7896e972-7e0c-41ff-ac17-145449e7c5df"
      },
      "source": [
        "%cd BERT4Rec-VAE-Pytorch/"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/BERT4Rec-VAE-Pytorch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Oq9_Sb-6bNS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "413ff685-5f9e-4f59-db32-c152ec36ee82"
      },
      "source": [
        "import sys\n",
        "sys.argv = ['--template train_bert']\n",
        "from main import *\n",
        "from templates import *\n",
        "# import subprocess\n",
        "# proc = subprocess.Popen(['python', 'main.py',  '--template train_bert', '--mode train'])\n",
        "print(sys.argv)\n",
        "args.template = \"test_bert\"\n",
        "set_template(args)\n",
        "model,test_loader=train()\n",
        "\n",
        "import torch\n",
        "\n",
        "#from conversion import *\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import pickle\n",
        "import pandas as pd\n",
        "from types import SimpleNamespace\n",
        "\n",
        "\n",
        "# Load best model file\n",
        "export_root = '/content/BERT4Rec-VAE-Pytorch/best_model'\n",
        "best_model = torch.load(os.path.join(export_root, 'models', 'best_acc_model.pth')).get('model_state_dict')\n",
        "print (list(best_model.keys()))\n",
        "# for key in list(best_model.keys()):\n",
        "#     best_model[key.replace('bert.', '')] = best_model.pop(key)\n",
        "\n",
        "\n",
        "model.load_state_dict(best_model)\n",
        "model.to(\"cuda\")\n",
        "model.eval()\n",
        "\n",
        "# Get sample tensor to load data into the model\n",
        "dataset = test_loader.dataset\n",
        "trainset = DataLoader(dataset=dataset,\n",
        "                      batch_size=1,\n",
        "                      shuffle=False,\n",
        "                      pin_memory=True)\n",
        "data = tqdm(trainset)\n",
        "ids_and_tensors = list(enumerate(data))\n",
        "\n",
        "# Load dataset (to get item mapping)\n",
        "export_root = '/content/BERT4Rec-VAE-Pytorch/Data/preprocessed/ml-1m_min_rating0-min_uc5-min_sc0-splitleave_one_out/dataset.pkl'\n",
        "data = pickle.load(open(export_root, \"rb\"))\n",
        "train = data['train']\n",
        "val = data['val']\n",
        "test = data['test']\n",
        "umap = data['umap']\n",
        "smap = data['smap']\n",
        "user_count = len(umap)\n",
        "item_count = len(smap)\n",
        "inv_map = {v: k for k, v in smap.items()}\n",
        "inv_user_map = {v: k for k, v in umap.items()}\n",
        "user_count, item_count\n",
        "\n",
        "# Function to get top predictions for a list of mal iDs\n",
        "def predict(input_movies, k=100):\n",
        "    user_id = 1111 # doesnt matter\n",
        "    source_movies = input_movies\n",
        "\n",
        "    with torch.no_grad():\n",
        "        movies=[]\n",
        "        for id in input_movies:\n",
        "          try: \n",
        "            movies.append(smap[id])\n",
        "\n",
        "          except KeyError:\n",
        "            print(id, \"is not an accepted input anime, ignoring\")\n",
        "        if movies==[]:\n",
        "          print(\"No valid anime, halting prediction\")\n",
        "          return\n",
        "        start = len(ids_and_tensors[user_id][1][0][0]) - len(movies)\n",
        "        for x in range(0, len(ids_and_tensors[user_id][1][0][0])):\n",
        "            ids_and_tensors[user_id][1][0][0][x] = 0\n",
        "        for x in range(start, len(ids_and_tensors[user_id][1][0][0])):\n",
        "            ids_and_tensors[user_id][1][0][0][x] = movies[x-start]\n",
        "        scores = model(ids_and_tensors[user_id][1][0].to('cuda'))\n",
        "        scores = scores[:, -1, :]\n",
        "        predictions = torch.topk(scores, k=k)\n",
        "        tops = predictions[1].cpu().numpy()[0]\n",
        "\n",
        "    output_movies = []\n",
        "    for x in range(0, len(tops)):\n",
        "        output_movies.append(inv_map[tops[x]])\n",
        "\n",
        "    final_results = [movie for movie in output_movies if movie not in source_movies]\n",
        "    source, prediction = source_movies, final_results\n",
        "\n",
        "    return source, prediction"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tqdm/std.py:648: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
            "  from pandas import Panel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['--template train_bert']\n",
            "Input 1 for ml-1m, 20 for ml-20m: 1\n",
            "0\n",
            "Folder created: /content/BERT4Rec-VAE-Pytorch/experiments/test_2022-01-11_3\n",
            "{'anneal_cap': 0.2,\n",
            " 'bert_dropout': 0.1,\n",
            " 'bert_hidden_units': 256,\n",
            " 'bert_mask_prob': 0.15,\n",
            " 'bert_max_len': 100,\n",
            " 'bert_num_blocks': 2,\n",
            " 'bert_num_heads': 4,\n",
            " 'best_metric': 'NDCG@10',\n",
            " 'dae_dropout': 0.5,\n",
            " 'dae_hidden_dim': 600,\n",
            " 'dae_latent_dim': 200,\n",
            " 'dae_num_hidden': 0,\n",
            " 'dataloader_code': 'bert',\n",
            " 'dataloader_random_seed': 0.0,\n",
            " 'dataset_code': 'ml-1m',\n",
            " 'dataset_split_seed': 98765,\n",
            " 'decay_step': 25,\n",
            " 'device': 'cuda',\n",
            " 'device_idx': '0',\n",
            " 'enable_lr_schedule': True,\n",
            " 'eval_set_size': 500,\n",
            " 'experiment_description': 'test',\n",
            " 'experiment_dir': 'experiments',\n",
            " 'find_best_beta': False,\n",
            " 'gamma': 1.0,\n",
            " 'log_period_as_iter': 12800,\n",
            " 'lr': 0.001,\n",
            " 'metric_ks': [1,\n",
            "               5,\n",
            "               10,\n",
            "               20,\n",
            "               50,\n",
            "               100],\n",
            " 'min_rating': 0,\n",
            " 'min_sc': 0,\n",
            " 'min_uc': 5,\n",
            " 'mode': 'train',\n",
            " 'model_code': 'bert',\n",
            " 'model_init_seed': 0,\n",
            " 'num_epochs': 100,\n",
            " 'num_gpu': 1,\n",
            " 'optimizer': 'Adam',\n",
            " 'split': 'leave_one_out',\n",
            " 'template': 'test_bert',\n",
            " 'test_batch_size': 128,\n",
            " 'test_negative_sample_size': 100,\n",
            " 'test_negative_sampler_code': 'random',\n",
            " 'test_negative_sampling_seed': 98765,\n",
            " 'testing': True,\n",
            " 'total_anneal_steps': 2000,\n",
            " 'train_batch_size': 128,\n",
            " 'train_negative_sample_size': 0,\n",
            " 'train_negative_sampler_code': 'random',\n",
            " 'train_negative_sampling_seed': 0,\n",
            " 'trainer_code': 'bert',\n",
            " 'vae_dropout': 0.5,\n",
            " 'vae_hidden_dim': 600,\n",
            " 'vae_latent_dim': 200,\n",
            " 'vae_num_hidden': 0,\n",
            " 'val_batch_size': 128,\n",
            " 'weight_decay': 0}\n",
            "Already preprocessed. Skip preprocessing\n",
            "Negatives samples exist. Loading.\n",
            "Negatives samples exist. Loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 364/234882 [00:00<01:04, 3629.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['bert.embedding.token.weight', 'bert.embedding.position.pe.weight', 'bert.transformer_blocks.0.attention.linear_layers.0.weight', 'bert.transformer_blocks.0.attention.linear_layers.0.bias', 'bert.transformer_blocks.0.attention.linear_layers.1.weight', 'bert.transformer_blocks.0.attention.linear_layers.1.bias', 'bert.transformer_blocks.0.attention.linear_layers.2.weight', 'bert.transformer_blocks.0.attention.linear_layers.2.bias', 'bert.transformer_blocks.0.attention.output_linear.weight', 'bert.transformer_blocks.0.attention.output_linear.bias', 'bert.transformer_blocks.0.feed_forward.w_1.weight', 'bert.transformer_blocks.0.feed_forward.w_1.bias', 'bert.transformer_blocks.0.feed_forward.w_2.weight', 'bert.transformer_blocks.0.feed_forward.w_2.bias', 'bert.transformer_blocks.0.input_sublayer.norm.a_2', 'bert.transformer_blocks.0.input_sublayer.norm.b_2', 'bert.transformer_blocks.0.output_sublayer.norm.a_2', 'bert.transformer_blocks.0.output_sublayer.norm.b_2', 'bert.transformer_blocks.1.attention.linear_layers.0.weight', 'bert.transformer_blocks.1.attention.linear_layers.0.bias', 'bert.transformer_blocks.1.attention.linear_layers.1.weight', 'bert.transformer_blocks.1.attention.linear_layers.1.bias', 'bert.transformer_blocks.1.attention.linear_layers.2.weight', 'bert.transformer_blocks.1.attention.linear_layers.2.bias', 'bert.transformer_blocks.1.attention.output_linear.weight', 'bert.transformer_blocks.1.attention.output_linear.bias', 'bert.transformer_blocks.1.feed_forward.w_1.weight', 'bert.transformer_blocks.1.feed_forward.w_1.bias', 'bert.transformer_blocks.1.feed_forward.w_2.weight', 'bert.transformer_blocks.1.feed_forward.w_2.bias', 'bert.transformer_blocks.1.input_sublayer.norm.a_2', 'bert.transformer_blocks.1.input_sublayer.norm.b_2', 'bert.transformer_blocks.1.output_sublayer.norm.a_2', 'bert.transformer_blocks.1.output_sublayer.norm.b_2', 'out.weight', 'out.bias']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 234882/234882 [01:00<00:00, 3863.80it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "IXau6BfR-y9y",
        "outputId": "8aa1cafa-4f8f-42b5-e5e7-f59b2aff0977"
      },
      "source": [
        "#Print top 10 recommendations\n",
        "x,y = predict([22319,31240,30831,19815])\n",
        "# Above anime in order^:\n",
        "#  tokyo ghoul, re zero, konosuba, no game no life\n",
        "df=pd.DataFrame(y)\n",
        "df[:10]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-fac6ddbf-3f22-4cf9-a683-64cbf4608c7e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>32937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>31043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>15809</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>30276</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>21881</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>22199</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>18679</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>20507</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>10793</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>23273</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fac6ddbf-3f22-4cf9-a683-64cbf4608c7e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fac6ddbf-3f22-4cf9-a683-64cbf4608c7e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fac6ddbf-3f22-4cf9-a683-64cbf4608c7e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       0\n",
              "0  32937\n",
              "1  31043\n",
              "2  15809\n",
              "3  30276\n",
              "4  21881\n",
              "5  22199\n",
              "6  18679\n",
              "7  20507\n",
              "8  10793\n",
              "9  23273"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "counter=0\n",
        "for x in df.itertuples():\n",
        "  if counter == 10:\n",
        "    break\n",
        "  counter+=1\n",
        "  print(\"https://myanimelist.net/anime/\"+str(x[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xb2rOhxTX-Os",
        "outputId": "e2d1cb15-05fe-429e-a80b-477e1f1064d3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://myanimelist.net/anime/32937\n",
            "https://myanimelist.net/anime/31043\n",
            "https://myanimelist.net/anime/15809\n",
            "https://myanimelist.net/anime/30276\n",
            "https://myanimelist.net/anime/21881\n",
            "https://myanimelist.net/anime/22199\n",
            "https://myanimelist.net/anime/18679\n",
            "https://myanimelist.net/anime/20507\n",
            "https://myanimelist.net/anime/10793\n",
            "https://myanimelist.net/anime/23273\n"
          ]
        }
      ]
    }
  ]
}