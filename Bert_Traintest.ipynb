{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Untitled",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYY2YbfNDHy4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WiJtVpCGqCxu",
        "outputId": "4657d147-1822-4c2b-c0f0-3dc2905878e1"
      },
      "source": [
        "!git clone https://github.com/jaywonchung/BERT4Rec-VAE-Pytorch  # clone repo"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'BERT4Rec-VAE-Pytorch'...\n",
            "remote: Enumerating objects: 166, done.\u001b[K\n",
            "remote: Total 166 (delta 0), reused 0 (delta 0), pack-reused 166\u001b[K\n",
            "Receiving objects: 100% (166/166), 3.05 MiB | 1.91 MiB/s, done.\n",
            "Resolving deltas: 100% (61/61), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBVw9iqQqQXP",
        "outputId": "98816a09-9fc0-4e56-f1c1-7fa3579c69f6"
      },
      "source": [
        "%cd BERT4Rec-VAE-Pytorch/\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/BERT4Rec-VAE-Pytorch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJyHn29fqphh",
        "outputId": "f9eb2ce5-1047-45ca-9026-03c4dacfb11a"
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wget==3.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (3.2)\n",
            "Requirement already satisfied: tqdm==4.36.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (4.36.1)\n",
            "Requirement already satisfied: numpy==1.16.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (1.16.2)\n",
            "Requirement already satisfied: torch==1.3.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (1.3.0)\n",
            "Requirement already satisfied: tb-nightly==2.1.0a20191121 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (2.1.0a20191121)\n",
            "Requirement already satisfied: pandas==0.25.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (0.25.0)\n",
            "Requirement already satisfied: scipy==1.3.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (1.3.2)\n",
            "Requirement already satisfied: future==0.18.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (0.18.2)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tb-nightly==2.1.0a20191121->-r requirements.txt (line 5)) (1.42.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly==2.1.0a20191121->-r requirements.txt (line 5)) (3.17.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tb-nightly==2.1.0a20191121->-r requirements.txt (line 5)) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly==2.1.0a20191121->-r requirements.txt (line 5)) (57.4.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tb-nightly==2.1.0a20191121->-r requirements.txt (line 5)) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tb-nightly==2.1.0a20191121->-r requirements.txt (line 5)) (0.4.6)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly==2.1.0a20191121->-r requirements.txt (line 5)) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tb-nightly==2.1.0a20191121->-r requirements.txt (line 5)) (0.37.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tb-nightly==2.1.0a20191121->-r requirements.txt (line 5)) (3.3.6)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tb-nightly==2.1.0a20191121->-r requirements.txt (line 5)) (0.12.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly==2.1.0a20191121->-r requirements.txt (line 5)) (2.23.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas==0.25.0->-r requirements.txt (line 6)) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from pandas==0.25.0->-r requirements.txt (line 6)) (2.8.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tb-nightly==2.1.0a20191121->-r requirements.txt (line 5)) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tb-nightly==2.1.0a20191121->-r requirements.txt (line 5)) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tb-nightly==2.1.0a20191121->-r requirements.txt (line 5)) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tb-nightly==2.1.0a20191121->-r requirements.txt (line 5)) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tb-nightly==2.1.0a20191121->-r requirements.txt (line 5)) (4.8.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tb-nightly==2.1.0a20191121->-r requirements.txt (line 5)) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tb-nightly==2.1.0a20191121->-r requirements.txt (line 5)) (3.6.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tb-nightly==2.1.0a20191121->-r requirements.txt (line 5)) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tb-nightly==2.1.0a20191121->-r requirements.txt (line 5)) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tb-nightly==2.1.0a20191121->-r requirements.txt (line 5)) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tb-nightly==2.1.0a20191121->-r requirements.txt (line 5)) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tb-nightly==2.1.0a20191121->-r requirements.txt (line 5)) (2021.10.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tb-nightly==2.1.0a20191121->-r requirements.txt (line 5)) (3.1.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wK4y6RFNqTG_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56ed60c0-d895-4624-9038-54749f01df96"
      },
      "source": [
        "!python main.py --template train_bert"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tqdm/std.py:648: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
            "  from pandas import Panel\n",
            "Input 1 for ml-1m, 20 for ml-20m: 1\n",
            "0\n",
            "Folder created: /content/BERT4Rec-VAE-Pytorch/experiments/test_2022-01-07_37\n",
            "{'anneal_cap': 0.2,\n",
            " 'bert_dropout': 0.1,\n",
            " 'bert_hidden_units': 256,\n",
            " 'bert_mask_prob': 0.15,\n",
            " 'bert_max_len': 100,\n",
            " 'bert_num_blocks': 2,\n",
            " 'bert_num_heads': 4,\n",
            " 'best_metric': 'NDCG@10',\n",
            " 'dae_dropout': 0.5,\n",
            " 'dae_hidden_dim': 600,\n",
            " 'dae_latent_dim': 200,\n",
            " 'dae_num_hidden': 0,\n",
            " 'dataloader_code': 'bert',\n",
            " 'dataloader_random_seed': 0.0,\n",
            " 'dataset_code': 'ml-1m',\n",
            " 'dataset_split_seed': 98765,\n",
            " 'decay_step': 25,\n",
            " 'device': 'cuda',\n",
            " 'device_idx': '0',\n",
            " 'enable_lr_schedule': True,\n",
            " 'eval_set_size': 500,\n",
            " 'experiment_description': 'test',\n",
            " 'experiment_dir': 'experiments',\n",
            " 'find_best_beta': False,\n",
            " 'gamma': 1.0,\n",
            " 'log_period_as_iter': 12800,\n",
            " 'lr': 0.001,\n",
            " 'metric_ks': [1,\n",
            "               5,\n",
            "               10,\n",
            "               20,\n",
            "               50,\n",
            "               100],\n",
            " 'min_rating': 0,\n",
            " 'min_sc': 0,\n",
            " 'min_uc': 5,\n",
            " 'mode': 'train',\n",
            " 'model_code': 'bert',\n",
            " 'model_init_seed': 0,\n",
            " 'num_epochs': 100,\n",
            " 'num_gpu': 1,\n",
            " 'optimizer': 'Adam',\n",
            " 'split': 'leave_one_out',\n",
            " 'template': 'train_bert',\n",
            " 'test_batch_size': 128,\n",
            " 'test_negative_sample_size': 100,\n",
            " 'test_negative_sampler_code': 'random',\n",
            " 'test_negative_sampling_seed': 98765,\n",
            " 'testing': False,\n",
            " 'total_anneal_steps': 2000,\n",
            " 'train_batch_size': 128,\n",
            " 'train_negative_sample_size': 0,\n",
            " 'train_negative_sampler_code': 'random',\n",
            " 'train_negative_sampling_seed': 0,\n",
            " 'trainer_code': 'bert',\n",
            " 'vae_dropout': 0.5,\n",
            " 'vae_hidden_dim': 600,\n",
            " 'vae_latent_dim': 200,\n",
            " 'vae_num_hidden': 0,\n",
            " 'val_batch_size': 128,\n",
            " 'weight_decay': 0}\n",
            "Already preprocessed. Skip preprocessing\n",
            "Negatives samples exist. Loading.\n",
            "Negatives samples exist. Loading.\n",
            "Val: N@1 0.011, N@5 0.027, N@10 0.042, R@1 0.011, R@5 0.043, R@10 0.091: 100% 1599/1599 [03:38<00:00,  7.33it/s]\n",
            "Update Best NDCG@10 Model at 1\n",
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:100: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
            "Epoch 1, loss 6.795 : 100% 1599/1599 [09:23<00:00,  2.84it/s]\n",
            "Val: N@1 0.505, N@5 0.677, N@10 0.706, R@1 0.505, R@5 0.826, R@10 0.915: 100% 1599/1599 [03:38<00:00,  7.31it/s]\n",
            "Update Best NDCG@10 Model at 1\n",
            "Epoch 2, loss 5.959 : 100% 1599/1599 [09:25<00:00,  2.83it/s]\n",
            "Val: N@1 0.546, N@5 0.711, N@10 0.737, R@1 0.546, R@5 0.852, R@10 0.931: 100% 1599/1599 [03:38<00:00,  7.31it/s]\n",
            "Update Best NDCG@10 Model at 2\n",
            "Epoch 3, loss 5.721 : 100% 1599/1599 [09:30<00:00,  2.80it/s]\n",
            "Val: N@1 0.563, N@5 0.725, N@10 0.750, R@1 0.563, R@5 0.863, R@10 0.939: 100% 1599/1599 [03:38<00:00,  7.33it/s]\n",
            "Update Best NDCG@10 Model at 3\n",
            "Epoch 4, loss 5.601 : 100% 1599/1599 [09:21<00:00,  2.85it/s]\n",
            "Val: N@1 0.573, N@5 0.732, N@10 0.756, R@1 0.573, R@5 0.868, R@10 0.940: 100% 1599/1599 [03:37<00:00,  7.34it/s]\n",
            "Update Best NDCG@10 Model at 4\n",
            "Epoch 5, loss 5.529 : 100% 1599/1599 [09:21<00:00,  2.85it/s]\n",
            "Val: N@1 0.579, N@5 0.738, N@10 0.761, R@1 0.579, R@5 0.873, R@10 0.944: 100% 1599/1599 [03:38<00:00,  7.31it/s]\n",
            "Update Best NDCG@10 Model at 5\n",
            "Epoch 6, loss 5.479 : 100% 1599/1599 [09:24<00:00,  2.83it/s]\n",
            "Val: N@1 0.581, N@5 0.740, N@10 0.763, R@1 0.581, R@5 0.875, R@10 0.945: 100% 1599/1599 [03:38<00:00,  7.31it/s]\n",
            "Update Best NDCG@10 Model at 6\n",
            "Epoch 7, loss 5.439 : 100% 1599/1599 [09:30<00:00,  2.80it/s]\n",
            "Val: N@1 0.587, N@5 0.744, N@10 0.767, R@1 0.587, R@5 0.877, R@10 0.946: 100% 1599/1599 [03:38<00:00,  7.32it/s]\n",
            "Update Best NDCG@10 Model at 7\n",
            "Epoch 8, loss 5.404 : 100% 1599/1599 [09:23<00:00,  2.84it/s]\n",
            "Val: N@1 0.586, N@5 0.744, N@10 0.767, R@1 0.586, R@5 0.877, R@10 0.947: 100% 1599/1599 [03:38<00:00,  7.31it/s]\n",
            "Epoch 9, loss 5.395 :   4% 71/1599 [00:25<08:54,  2.86it/s]Traceback (most recent call last):\n",
            "  File \"main.py\", line 27, in <module>\n",
            "    train()\n",
            "  File \"main.py\", line 18, in train\n",
            "    trainer.train()\n",
            "  File \"/content/BERT4Rec-VAE-Pytorch/trainers/base.py\", line 71, in train\n",
            "    accum_iter = self.train_one_epoch(epoch, accum_iter)\n",
            "  File \"/content/BERT4Rec-VAE-Pytorch/trainers/base.py\", line 92, in train_one_epoch\n",
            "    loss.backward()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/tensor.py\", line 150, in backward\n",
            "    torch.autograd.backward(self, gradient, retain_graph, create_graph)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\", line 99, in backward\n",
            "    allow_unreachable=True)  # allow_unreachable flag\n",
            "KeyboardInterrupt\n",
            "Epoch 9, loss 5.395 :   4% 71/1599 [00:26<09:34,  2.66it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKAZkvNMTXX3",
        "outputId": "0783a056-7f12-49f9-f12d-90d5d74094d1"
      },
      "source": [
        "!unzip /content/content.zip -d /content/BERT4Rec-VAE-Pytorch/experiments"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/content.zip\n",
            "   creating: /content/BERT4Rec-VAE-Pytorch/experiments/content/BERT4Rec-VAE-Pytorch/experiments/test_2021-07-24_2/\n",
            "  inflating: /content/BERT4Rec-VAE-Pytorch/experiments/content/BERT4Rec-VAE-Pytorch/experiments/test_2021-07-24_2/config.json  \n",
            "   creating: /content/BERT4Rec-VAE-Pytorch/experiments/content/BERT4Rec-VAE-Pytorch/experiments/test_2021-07-24_2/models/\n",
            "  inflating: /content/BERT4Rec-VAE-Pytorch/experiments/content/BERT4Rec-VAE-Pytorch/experiments/test_2021-07-24_2/models/checkpoint-recent.pth  \n",
            "  inflating: /content/BERT4Rec-VAE-Pytorch/experiments/content/BERT4Rec-VAE-Pytorch/experiments/test_2021-07-24_2/models/best_acc_model.pth  \n",
            "   creating: /content/BERT4Rec-VAE-Pytorch/experiments/content/BERT4Rec-VAE-Pytorch/experiments/test_2021-07-24_2/logs/\n",
            "  inflating: /content/BERT4Rec-VAE-Pytorch/experiments/content/BERT4Rec-VAE-Pytorch/experiments/test_2021-07-24_2/logs/events.out.tfevents.1627149185.98b0e63be087.360.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_R2HzNQ1abc"
      },
      "source": [
        "!zip -r /content/folder /content/BERT4Rec-VAE-Pytorch/experiments/test_2021-07-24_2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2a3YmtSLjg32",
        "outputId": "b25e967e-8d1c-4f03-d149-91e1a39f9b6d"
      },
      "source": [
        "!pip uninstall pandas\n",
        "!pip install pandas==0.25.0"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: pandas 0.25.0\n",
            "Uninstalling pandas-0.25.0:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.7/dist-packages/pandas-0.25.0.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/pandas/*\n",
            "Proceed (y/n)? \u001b[31mERROR: Operation cancelled by user\u001b[0m\n",
            "Requirement already satisfied: pandas==0.25.0 in /usr/local/lib/python3.7/dist-packages (0.25.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas==0.25.0) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from pandas==0.25.0) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from pandas==0.25.0) (1.16.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.6.1->pandas==0.25.0) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrXZb5I30_vs",
        "outputId": "5ac453bc-5075-41f2-a977-de60adbeb661"
      },
      "source": [
        "%cd BERT4Rec-VAE-Pytorch/"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/BERT4Rec-VAE-Pytorch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Oq9_Sb-6bNS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16955cea-79c3-4993-8791-80a750e94ab5"
      },
      "source": [
        "import sys\n",
        "sys.argv = ['--template train_bert']\n",
        "from main import *\n",
        "from templates import *\n",
        "# import subprocess\n",
        "# proc = subprocess.Popen(['python', 'main.py',  '--template train_bert', '--mode train'])\n",
        "print(sys.argv)\n",
        "args.template = \"test_bert\"\n",
        "set_template(args)\n",
        "model,test_loader=train()\n",
        "\n",
        "import torch\n",
        "\n",
        "#from conversion import *\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import pickle\n",
        "import pandas as pd\n",
        "from types import SimpleNamespace\n",
        "\n",
        "\n",
        "# Load best model file\n",
        "export_root = 'experiments/test_2022-01-07_37'\n",
        "best_model = torch.load(os.path.join(export_root, 'models', 'best_acc_model.pth')).get('model_state_dict')\n",
        "print (list(best_model.keys()))\n",
        "# for key in list(best_model.keys()):\n",
        "#     best_model[key.replace('bert.', '')] = best_model.pop(key)\n",
        "\n",
        "\n",
        "model.load_state_dict(best_model)\n",
        "model.to(\"cuda\")\n",
        "model.eval()\n",
        "\n",
        "# Get sample tensor to load data into the model\n",
        "dataset = test_loader.dataset\n",
        "trainset = DataLoader(dataset=dataset,\n",
        "                      batch_size=1,\n",
        "                      shuffle=False,\n",
        "                      pin_memory=True)\n",
        "data = tqdm(trainset)\n",
        "ids_and_tensors = list(enumerate(data))\n",
        "\n",
        "# Load dataset (to get item mapping)\n",
        "export_root = '/content/BERT4Rec-VAE-Pytorch/Data/preprocessed/ml-1m_min_rating0-min_uc5-min_sc0-splitleave_one_out/dataset.pkl'\n",
        "data = pickle.load(open(export_root, \"rb\"))\n",
        "train = data['train']\n",
        "val = data['val']\n",
        "test = data['test']\n",
        "umap = data['umap']\n",
        "smap = data['smap']\n",
        "user_count = len(umap)\n",
        "item_count = len(smap)\n",
        "inv_map = {v: k for k, v in smap.items()}\n",
        "inv_user_map = {v: k for k, v in umap.items()}\n",
        "user_count, item_count\n",
        "\n",
        "# Function to get top predictions for a list of IMDB ids\n",
        "\"\"\" get top predictions from the model based on IMDB ids \"\"\"\n",
        "def predict(input_movies, k=100):\n",
        "    user_id = 1111 # arbitrary, doesn't matter\n",
        "    source_movies = input_movies\n",
        "\n",
        "    with torch.no_grad():\n",
        "        movies = [smap[id] for id in input_movies]\n",
        "        start = len(ids_and_tensors[user_id][1][0][0]) - len(movies)\n",
        "        for x in range(0, len(ids_and_tensors[user_id][1][0][0])):\n",
        "            ids_and_tensors[user_id][1][0][0][x] = 0\n",
        "        for x in range(start, len(ids_and_tensors[user_id][1][0][0])):\n",
        "            ids_and_tensors[user_id][1][0][0][x] = movies[x-start]\n",
        "        scores = model(ids_and_tensors[user_id][1][0].to('cuda'))\n",
        "        scores = scores[:, -1, :]\n",
        "        predictions = torch.topk(scores, k=k)\n",
        "        tops = predictions[1].cpu().numpy()[0]\n",
        "\n",
        "    output_movies = []\n",
        "    for x in range(0, len(tops)):\n",
        "        output_movies.append(inv_map[tops[x]])\n",
        "\n",
        "    final_results = [movie for movie in output_movies if movie not in source_movies]\n",
        "    source, prediction = source_movies, final_results\n",
        "\n",
        "    return source, prediction"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tqdm/std.py:648: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
            "  from pandas import Panel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['--template train_bert']\n",
            "Input 1 for ml-1m, 20 for ml-20m: 1\n",
            "0\n",
            "Folder created: /content/BERT4Rec-VAE-Pytorch/experiments/test_2022-01-07_38\n",
            "{'anneal_cap': 0.2,\n",
            " 'bert_dropout': 0.1,\n",
            " 'bert_hidden_units': 256,\n",
            " 'bert_mask_prob': 0.15,\n",
            " 'bert_max_len': 100,\n",
            " 'bert_num_blocks': 2,\n",
            " 'bert_num_heads': 4,\n",
            " 'best_metric': 'NDCG@10',\n",
            " 'dae_dropout': 0.5,\n",
            " 'dae_hidden_dim': 600,\n",
            " 'dae_latent_dim': 200,\n",
            " 'dae_num_hidden': 0,\n",
            " 'dataloader_code': 'bert',\n",
            " 'dataloader_random_seed': 0.0,\n",
            " 'dataset_code': 'ml-1m',\n",
            " 'dataset_split_seed': 98765,\n",
            " 'decay_step': 25,\n",
            " 'device': 'cuda',\n",
            " 'device_idx': '0',\n",
            " 'enable_lr_schedule': True,\n",
            " 'eval_set_size': 500,\n",
            " 'experiment_description': 'test',\n",
            " 'experiment_dir': 'experiments',\n",
            " 'find_best_beta': False,\n",
            " 'gamma': 1.0,\n",
            " 'log_period_as_iter': 12800,\n",
            " 'lr': 0.001,\n",
            " 'metric_ks': [1,\n",
            "               5,\n",
            "               10,\n",
            "               20,\n",
            "               50,\n",
            "               100],\n",
            " 'min_rating': 0,\n",
            " 'min_sc': 0,\n",
            " 'min_uc': 5,\n",
            " 'mode': 'train',\n",
            " 'model_code': 'bert',\n",
            " 'model_init_seed': 0,\n",
            " 'num_epochs': 100,\n",
            " 'num_gpu': 1,\n",
            " 'optimizer': 'Adam',\n",
            " 'split': 'leave_one_out',\n",
            " 'template': 'test_bert',\n",
            " 'test_batch_size': 128,\n",
            " 'test_negative_sample_size': 100,\n",
            " 'test_negative_sampler_code': 'random',\n",
            " 'test_negative_sampling_seed': 98765,\n",
            " 'testing': True,\n",
            " 'total_anneal_steps': 2000,\n",
            " 'train_batch_size': 128,\n",
            " 'train_negative_sample_size': 0,\n",
            " 'train_negative_sampler_code': 'random',\n",
            " 'train_negative_sampling_seed': 0,\n",
            " 'trainer_code': 'bert',\n",
            " 'vae_dropout': 0.5,\n",
            " 'vae_hidden_dim': 600,\n",
            " 'vae_latent_dim': 200,\n",
            " 'vae_num_hidden': 0,\n",
            " 'val_batch_size': 128,\n",
            " 'weight_decay': 0}\n",
            "Already preprocessed. Skip preprocessing\n",
            "Negatives samples exist. Loading.\n",
            "Negatives samples exist. Loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 579/204569 [00:00<00:35, 5783.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['bert.embedding.token.weight', 'bert.embedding.position.pe.weight', 'bert.transformer_blocks.0.attention.linear_layers.0.weight', 'bert.transformer_blocks.0.attention.linear_layers.0.bias', 'bert.transformer_blocks.0.attention.linear_layers.1.weight', 'bert.transformer_blocks.0.attention.linear_layers.1.bias', 'bert.transformer_blocks.0.attention.linear_layers.2.weight', 'bert.transformer_blocks.0.attention.linear_layers.2.bias', 'bert.transformer_blocks.0.attention.output_linear.weight', 'bert.transformer_blocks.0.attention.output_linear.bias', 'bert.transformer_blocks.0.feed_forward.w_1.weight', 'bert.transformer_blocks.0.feed_forward.w_1.bias', 'bert.transformer_blocks.0.feed_forward.w_2.weight', 'bert.transformer_blocks.0.feed_forward.w_2.bias', 'bert.transformer_blocks.0.input_sublayer.norm.a_2', 'bert.transformer_blocks.0.input_sublayer.norm.b_2', 'bert.transformer_blocks.0.output_sublayer.norm.a_2', 'bert.transformer_blocks.0.output_sublayer.norm.b_2', 'bert.transformer_blocks.1.attention.linear_layers.0.weight', 'bert.transformer_blocks.1.attention.linear_layers.0.bias', 'bert.transformer_blocks.1.attention.linear_layers.1.weight', 'bert.transformer_blocks.1.attention.linear_layers.1.bias', 'bert.transformer_blocks.1.attention.linear_layers.2.weight', 'bert.transformer_blocks.1.attention.linear_layers.2.bias', 'bert.transformer_blocks.1.attention.output_linear.weight', 'bert.transformer_blocks.1.attention.output_linear.bias', 'bert.transformer_blocks.1.feed_forward.w_1.weight', 'bert.transformer_blocks.1.feed_forward.w_1.bias', 'bert.transformer_blocks.1.feed_forward.w_2.weight', 'bert.transformer_blocks.1.feed_forward.w_2.bias', 'bert.transformer_blocks.1.input_sublayer.norm.a_2', 'bert.transformer_blocks.1.input_sublayer.norm.b_2', 'bert.transformer_blocks.1.output_sublayer.norm.a_2', 'bert.transformer_blocks.1.output_sublayer.norm.b_2', 'out.weight', 'out.bias']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 204569/204569 [00:43<00:00, 4727.30it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "IXau6BfR-y9y",
        "outputId": "acc09a4c-4ea3-4a2a-e6ce-a3bf66078492"
      },
      "source": [
        "x,y = predict([30831,32937,29803,31240,21])\n",
        "df=pd.DataFrame(y)\n",
        "df[:10]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-d60fc381-997d-4c2a-9420-3e284c077b00\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>25777</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>32282</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>22535</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>30240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>31043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>32281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>34134</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>30276</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>22199</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>19815</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d60fc381-997d-4c2a-9420-3e284c077b00')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d60fc381-997d-4c2a-9420-3e284c077b00 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d60fc381-997d-4c2a-9420-3e284c077b00');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       0\n",
              "0  25777\n",
              "1  32282\n",
              "2  22535\n",
              "3  30240\n",
              "4  31043\n",
              "5  32281\n",
              "6  34134\n",
              "7  30276\n",
              "8  22199\n",
              "9  19815"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    }
  ]
}